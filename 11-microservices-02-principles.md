
# Домашнее задание к занятию «Микросервисы: принципы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: API Gateway 

Предложите решение для обеспечения реализации API Gateway. Составьте сравнительную таблицу возможностей различных программных решений. На основе таблицы сделайте выбор решения.

Решение должно соответствовать следующим требованиям:
- маршрутизация запросов к нужному сервису на основе конфигурации,
- возможность проверки аутентификационной информации в запросах,
- обеспечение терминации HTTPS.

Обоснуйте свой выбор.
--------------------------------------------------
## Ответ №1  
### Предложение по решению для API Gateway

На основе анализа современных решений, я рекомендую использовать **Kong Gateway** в качестве ядра API Gateway для вашей системы.

**Краткое обоснование:** Kong обладает идеальным балансом между производительностью, богатой функциональностью (благодаря экосистеме плагинов), простотой эксплуатации и надежностью. Он основан на технологии **Nginx** и **OpenResty**, что гарантирует высокую производительность и стабильность. Его модель плагинов позволяет гибко настраивать поведение шлюза без написания кода, что соответствует всем вашим требованиям.

---

### Сравнительная таблица возможностей программных решений

В таблице рассмотрены наиболее популярные и проверенные в production-средах решения.

| Критерий / Решение            | Kong Gateway                                                | NGINX (как API Gateway)                                                       | Traefik                                                    | Gloo Edge (от Solo.io)                           | Spring Cloud Gateway                     |
| ----------------------------- | ----------------------------------------------------------- | ----------------------------------------------------------------------------- | ---------------------------------------------------------- | ------------------------------------------------ | ---------------------------------------- |
| **Тип решения**               | Специализированный API Gateway на базе OpenResty            | Универсальный веб-сервер / обратный прокси с возможностями API GW             | Edge-роутер / API Gateway                                  | API Gateway на базе Envoy                        | API Gateway на базе Spring (JVM)         |
| **Маршрутизация**             | ✅ (На основе путей, хостов, заголовков)                     | ✅ (Гибкая, на основе `location` в конфиге)                                    | ✅ (Динамическая, на основе меток Docker/K8s)               | ✅ (Продвинутая, на основе gRPC, GraphQL, REST)   | ✅ (Гибкая, на основе предикатов Spring)  |
| **Аутентификация**            | ✅ (Множество плагинов: JWT, Key-Auth, OAuth2, LDAP)         | ⚠️ (Базовая - через `auth_basic`, сложная требует скриптов Lua/OpenID Connect) | ✅ (Middlewares для Basic Auth, Digest, OIDC)               | ✅ (Расширенные плагины, интеграция с Auth0, OPA) | ✅ (Интеграция с Spring Security)         |
| **Терминация HTTPS**          | ✅ (Встроенная поддержка, обновление сертификатов через API) | ✅ (Эталонная реализация)                                                      | ✅ (Автоматическое получение сертификатов от Let's Encrypt) | ✅ (Встроенная, поддержка mTLS)                   | ✅ (Стандартная для Spring)               |
| **Производительность**        | Очень высокая (Nginx + LuaJIT)                              | Эталонно высокая                                                              | Высокая (на Go)                                            | Очень высокая (на базе Envoy)                    | Средняя (зависит от JVM)                 |
| **Динамическая конфигурация** | ✅ (Через БД или Declarative Config)                         | ⚠️ (Требует перезагрузки или Lua-скриптов)                                     | ✅ (Горячая перезагрузка, провайдеры)                       | ✅ (Through Envoy's xDS API)                      | ✅ (Интеграция с Spring Cloud Config)     |
| **Экосистема и плагины**      | ✅ (Огромное сообщество, множество готовых плагинов)         | ⚠️ (Требует кастомной разработки на Lua)                                       | ✅ (Много Middlewares, сообщество растет)                   | ✅ (Много плагинов, акцент на Service Mesh)       | ✅ (Можно использовать любые бины Spring) |
| **Управление и UI**           | ✅ (Kong Manager - Enterprise, Konga - OSS)                  | ❌ (Только конфиг-файлы)                                                       | ✅ (Встроенная Dashboard)                                   | ✅ (Gloo Portal, UI для управления)               | ❌ (Только через конфиги / аннотации)     |
| **Orchestration (K8s)**       | ✅ (Отличная интеграция через CRD Ingress)                   | ✅ (Ingress Controller)                                                        | ✅ (Нативный Ingress Controller)                            | ✅ (Нативный Ingress / Gateway API Controller)    | ✅ (Может работать внутри K8s)            |
| **Сложность освоения**        | Средняя                                                     | Высокая (для сложных сценариев)                                               | Низкая                                                     | Средняя / Высокая                                | Средняя (для Java-разработчиков)         |
| **Логирование и мониторинг**  | ✅ (Плагины для Prometheus, Datadog, Zipkin и др.)           | ✅ (Доступ к логам, может быть интегрирован)                                   | ✅ (Встроенная метрики, интеграции)                         | ✅ (Интеграция с Observability стеком)            | ✅ (Через Actuator и Spring生态)          |

---

### Обоснование выбора Kong Gateway

1.  **Полное соответствие требованиям:**
    *   **Маршрутизация:** Kong предоставляет мощный и гибкий механизм маршрутизации на основе `Routes` и `Services`. Вы можете определять правила на основе URI-пути, хоста, заголовков и методов HTTP.
    *   **Аутентификация:** Это одна из сильнейших сторон Kong. Плагин **JWT** (JSON Web Token) позволяет легко проверять подпись и claims токенов в запросах. Также доступны плагины для базовой аутентификации, OAuth 2.0, ACL (контроль доступа), что полностью закрывает требование.
    *   **Терминация HTTPS:** Kong легко настраивается на работу с SSL-сертификатами. Сертификаты можно загружать через Admin API, что позволяет автоматизировать процесс их обновления (например, с помощью cert-manager в Kubernetes).

2.  **Производительность и надежность:** Построенный на основе Nginx, Kong наследует его асинхронную, событийно-ориентированную архитектуру. Это гарантирует низкую задержку и высокую пропускную способность даже под большой нагрузкой, что критически важно для центрального узла всей системы.

3.  **Экосистема и расширяемость:** Модель плагинов Kong — его ключевое преимущество. Помимо аутентификации, вы получаете "из коробки" возможности для:
    *   **Rate Limiting** (ограничение частоты запросов).
    *   **Caching** (кэширование ответов).
    *   **Logging** (отправка логов в Syslog, HTTP-эндпоинты, Kafka и др.).
    *   **Monitoring** (метрики для Prometheus).
    *   **Security** (CORS, IP restriction, Bot detection).
    Это позволяет гибко развивать шлюз, не прибегая к разработке кастомного кода.

4.  **Операционная зрелость:**
    *   **Динамическая конфигурация:** Kong может хранить конфигурацию в базе данных (PostgreSQL/Cassandra), что позволяет обновлять маршруты и настройки плагинов "на лету" без перезагрузки.
    *   **Kubernetes-Native:** Существует официальный **Kong Ingress Controller**, который позволяет управлять шлюзом декларативно через привычные Kubernetes-ресурсы (Ingress, Custom Resources). Это идеально вписывается в современный DevOps-стек.
    *   **Сообщество и поддержка:** Kong имеет большое и активное сообщество, а также предлагает коммерческую Enterprise-версию с дополнительными функциями и поддержкой, что важно для крупной компании.

### Альтернативы

*   **NGINX:** Отличный выбор, если вам нужен максимальный контроль и вы готовы поддерживать кастомные Lua-скрипты для сложной логики. Он может быть выгоднее в чисто "проксирующих" сценариях без богатой логики плагинов.
*   **Traefik:** Идеален для environments, где доминирует Docker/Kubernetes, благодаря автоматическому обнаружению сервисов. Проще в начальной настройке, но экосистема плагинов пока уступает Kong.
*   **Spring Cloud Gateway:** Логичный выбор, если вся ваша экосистема построена на Spring (Java). Однако его производительность будет ниже, чем у решений на C/Go, и он привязывает вас к JVM-стеку.

### Итоговое предложение по внедрению

Для разработки и эксплуатации в крупной компании на основе микросервисной архитектуры я предлагаю:

1.  **Выбор продукта:** **Kong Gateway (Open Source version)**.
2.  **Способ развертывания:** В качестве **Kong Ingress Controller** внутри Kubernetes-кластера. Это позволит управлять маршрутизацией декларативно с помощью YAML-манифестов, интегрировать их в GitOps-процессы (например, с ArgoCD) и легко масштабировать.
3.  **Схема работы:**
    *   Все входящие HTTPS-запросы приходят на Kong.
    *   Kong проверяет SSL-сертификат.
    *   Плагин аутентификации (например, JWT) проверяет наличие и валидность токена в заголовке запроса.
    *   После успешной аутентификации Kong направляет запрос к соответствующему backend-сервису на основе правил маршрутизации.

Данное решение является надежным, производительным, соответствует всем заявленным требованиям и отлично вписывается в современные DevOps-практики.  
------------------------------------------
## Задача 2: Брокер сообщений

Составьте таблицу возможностей различных брокеров сообщений. На основе таблицы сделайте обоснованный выбор решения.

Решение должно соответствовать следующим требованиям:
- поддержка кластеризации для обеспечения надёжности,
- хранение сообщений на диске в процессе доставки,
- высокая скорость работы,
- поддержка различных форматов сообщений,
- разделение прав доступа к различным потокам сообщений,
- простота эксплуатации.

Обоснуйте свой выбор.

## Ответ №2  
Отличная задача! Проведем сравнительный анализ популярных брокеров сообщений на основе заданных требований и обоснуем выбор.

### Сравнительная таблица брокеров сообщений

| Критерий                                   | Apache Kafka                                                                                   | RabbitMQ                                                                                | Apache Pulsar                                                                                        | NATS (JetStream)                                                                          | Redis Pub/Sub (Streams)                                                      |
| :----------------------------------------- | :--------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------- |
| **Поддержка кластеризации для надёжности** | **Да** (партиции реплицируются между брокерами). Высокая отказоустойчивость.                   | **Да** (кластеры с зеркалированием очередей). Требует тонкой настройки для HA.          | **Да** (многоуровневая архитектура: брокеры + BookKeeper). Отличная отказоустойчивость "из коробки". | **Да** (кластер с репликацией на уровне JetStream). Проще, чем у Kafka.                   | **Да** (Redis Cluster). Sentinel для HA. Надежность зависит от конфигурации. |
| **Хранение на диске**                      | **Да** (по умолчанию). Сообщения хранятся как лог.                                             | **Да** (сообщения могут быть устойчивыми).                                              | **Да** (сообщения хранятся в BookKeeper + долгосрочно в объектном хранилище).                        | **Да** (с использованием JetStream).                                                      | **Частично** (Pub/Sub - нет, **Streams** - да, с опциями сохранения).        |
| **Высокая скорость работы**                | **Очень высокая** (последовательный I/O, нулевое копирование). Пиковая пропускная способность. | **Высокая** (для большинства сценариев). Может уступать Kafka при огромных объемах.     | **Очень высокая** (разделение ввода/вывода). Сравнима с Kafka.                                       | **Чрезвычайно высокая** (минимальные задержки). Идеален для сценариев в реальном времени. | **Чрезвычайно высокая** (в памяти). Но зависит от durability.                |
| **Поддержка форматов**                     | **Агностик** (сообщения - byte[]). Ответственность на производителе/потребителе.               | **Агностик** (тело сообщения - byte[]). Есть заголовки для метаданных.                  | **Агностик** (как и Kafka). Поддерживает Schema Registry.                                            | **Агностик** (как и Kafka).                                                               | **Агностик** (сообщения как строки/бинарные данные).                         |
| **Разделение прав доступа**                | **Да** (через SASL/SSL, ACL на топики, операции). Гибко и мощно.                               | **Да** (vhosts, пользователи, права на чтение/запись/конфигурирование). Очень наглядно. | **Да** (многоуровневая система неймспейсов и топиков, ролевой доступ).                               | **Да** (пользователи, аккаунты, разрешения на субъекты).                                  | **Базовая** (парольная аутентификация). Нет тонких ACL на потоки в кластере. |
| **Простота эксплуатации**                  | **Средняя/Сложная**                                                                            | **Простая/Средняя**                                                                     | **Средняя/Сложная**                                                                                  | **Простая**                                                                               | **Очень простая**                                                            |
| **Ключевые особенности**                   | Лог-центричный, потоковая обработка, повторное чтение.                                         | Гибкая маршрутизация (Exchange), очереди задач.                                         | Многоуровневое хранение, объединяет модели очередей и топиков.                                       | "Просто работает", минимальные задержки, простой кластер.                                 | Простота, скорость, структуры данных.                                        |

---

### Обоснованный выбор решения

Универсального решения "на все случаи жизни" не существует. Выбор зависит от специфики проекта. Рассмотрим два наиболее подходящих кандидата для общих требований задачи и один — для специфичных высоконагруженных сценариев.

#### 1. Основной выбор: **RabbitMQ**

**RabbitMQ является наиболее сбалансированным и подходящим выбором для подавляющего большинства проектов, которые подпадают под указанные требования.**

**Обоснование:**

*   **Поддержка кластеризации и надёжность:** Кластеры RabbitMQ с зеркалированием очередей обеспечивают отличную отказоустойчивость. Хотя настройка HA требует внимания, это хорошо документированный и отработанный на практике процесс.
*   **Хранение на диске:** Устойчивые (persistent) сообщения записываются на диск и не теряются при перезагрузке брокера. Это поведение легко настраивается.
*   **Скорость:** RabbitMQ обладает высокой скоростью, достаточной для 95% современных приложений (десятки-сотни тысяч сообщений в секунду). Он редко становится узким местом.
*   **Разделение прав доступа:** Механизм `vhost` (виртуальных хостов) и гибких разрешений является золотым стандартом для изоляции сред и приложений. Это интуитивно понятно и мощно.
*   **Простота эксплуатации:** **Это ключевое преимущество.** RabbitMQ невероятно прост в развертывании, администрировании и мониторингу. Веб-интерфейс предоставляет исчерпывающую информацию о состоянии очередей, потреблении и проблемах. Сообщество огромно, а количество готовых операторов для Kubernetes (например, от Bitnami) делает его развертывание тривиальным заданием.

**Вывод:** RabbitMQ идеально сочетает в себе мощь, надежность и **простоту эксплуатации**, что делает его идеальным выбором для микросервисных архитектур, фоновых задач и систем, где важна предсказуемость и удобство поддержки.

---

#### 2. Альтернативный выбор для высоконагруженных и аналитических систем: **Apache Kafka**

**Выбирайте Kafka, если ваши требования смещены в сторону обработки огромных потоков данных (тысячи сообщений в секунду и более), долгосрочного хранения и потоковой обработки.**

**Обоснование:**

*   **Надёжность и производительность:** Архитектура, основанная на распределенном логе, обеспечивает непревзойденную пропускную способность и отказоустойчивость. Данные реплицируются и надежно хранятся.
*   **Хранение на диске:** Это основная модель работы. Сообщения хранятся долго, и потребители могут перечитывать исторические данные с любого места — это уникальная возможность.
*   **Разделение прав доступа:** Механизм ACL в Kafka очень детализированный и мощный, что критически важно в больших многокомандных средах.
*   **Простота эксплуатации:** **Главный минус.** Kafka значительно сложнее в эксплуатации, чем RabbitMQ. Требует глубоких знаний для тонкой настройки, мониторинга и устранения неполадок. Это "тяжелая артиллерия".

**Вывод:** Kafka — это король в мире big data и event-driven архитектур, где важна не просто доставка, а **поток событий как источник истины**. Но за его мощь приходится платить сложностью эксплуатации.

---

#### 3. Перспективный современный выбор: **Apache Pulsar**

**Pulsar — это современный конкурент Kafka, который стоит рассмотреть для greenfield-проектов, где важна гибкость моделей потребления (очереди и топики одновременно) и многоарендность.**

**Обоснование:**

*   **Архитектура:** Разделение уровней брокеров (обработка) и BookKeeper (хранение) дает великолепную отказоустойчивость и масштабируемость "из коробки".
*   **Гибкость:** Поддерживает как модель "очереди" (с конкурирующими потребителями), так и модель "топика" (как у Kafka), что избавляет от необходимости выбора между RabbitMQ и Kafka.
*   **Надёжность и производительность:** Сравнима с Kafka, а в некоторых аспектах (гео-репликация, многоуровневое хранение) — превосходит.
*   **Простота эксплуатации:** Проще, чем Kafka, благодаря своей архитектуре, но все еще сложнее RabbitMQ. Экосистема и сообщество пока меньше, чем у двух лидеров.

**Вывод:** Pulsar — отличная, перспективная платформа, которая может стать будущим стандартом. Если ваша команда готова к использованию более новых технологий, это достойный и мощный вариант.

### Итоговый вердикт

| Сценарий                                                          | Рекомендуемый брокер | Краткое обоснование                                                                       |
| :---------------------------------------------------------------- | :------------------- | :---------------------------------------------------------------------------------------- |
| **Универсальный случай (микросервисы, фоновые задачи)**           | **RabbitMQ**         | Идеальный баланс функциональности, надежности и **простоты эксплуатации**.                |
| **Высоконагруженные потоки данных, аналитика, событийные архивы** | **Apache Kafka**     | Максимальная производительность и надежность для big data, но высокая стоимость владения. |
| **Современный проект, требующий гибкости (очереди + топики)**     | **Apache Pulsar**    | Мощная и гибкая платформа "все-в-одном", перспективный, но менее распространенный выбор.  |

**Для задачи, сформулированной в условии, где важна не только функциональность, но и "простота эксплуатации", я настоятельно рекомендую `RabbitMQ`.** Он полностью удовлетворяет всем заявленным требованиям и при этом является самым простым в поддержке и понимании решением из рассмотренных.  
------------------------------------------


## Задача 3: API Gateway * (необязательная)

### Есть три сервиса:

**minio**
- хранит загруженные файлы в бакете images,
- S3 протокол,

**uploader**
- принимает файл, если картинка сжимает и загружает его в minio,
- POST /v1/upload,

**security**
- регистрация пользователя POST /v1/user,
- получение информации о пользователе GET /v1/user,
- логин пользователя POST /v1/token,
- проверка токена GET /v1/token/validation.

### Необходимо воспользоваться любым балансировщиком и сделать API Gateway:

**POST /v1/register**
1. Анонимный доступ.
2. Запрос направляется в сервис security POST /v1/user.

**POST /v1/token**
1. Анонимный доступ.
2. Запрос направляется в сервис security POST /v1/token.

**GET /v1/user**
1. Проверка токена. Токен ожидается в заголовке Authorization. Токен проверяется через вызов сервиса security GET /v1/token/validation/.
2. Запрос направляется в сервис security GET /v1/user.

**POST /v1/upload**
1. Проверка токена. Токен ожидается в заголовке Authorization. Токен проверяется через вызов сервиса security GET /v1/token/validation/.
2. Запрос направляется в сервис uploader POST /v1/upload.

**GET /v1/user/{image}**
1. Проверка токена. Токен ожидается в заголовке Authorization. Токен проверяется через вызов сервиса security GET /v1/token/validation/.
2. Запрос направляется в сервис minio GET /images/{image}.

### Ожидаемый результат

Результатом выполнения задачи должен быть docker compose файл, запустив который можно локально выполнить следующие команды с успешным результатом.
Предполагается, что для реализации API Gateway будет написан конфиг для NGinx или другого балансировщика нагрузки, который будет запущен как сервис через docker-compose и будет обеспечивать балансировку и проверку аутентификации входящих запросов.
Авторизация
curl -X POST -H 'Content-Type: application/json' -d '{"login":"bob", "password":"qwe123"}' http://localhost/token

**Загрузка файла**

curl -X POST -H 'Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJib2IifQ.hiMVLmssoTsy1MqbmIoviDeFPvo-nCd92d4UFiN2O2I' -H 'Content-Type: octet/stream' --data-binary @yourfilename.jpg http://localhost/upload

**Получение файла**
curl -X GET http://localhost/images/4e6df220-295e-4231-82bc-45e4b1484430.jpg

---

#### [Дополнительные материалы: как запускать, как тестировать, как проверить](https://github.com/netology-code/devkub-homeworks/tree/main/11-microservices-02-principles)

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
