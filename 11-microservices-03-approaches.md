# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.
---------------------------

## Решение №1

Я предлагаю использовать связку из **GitLab (Self-Managed)** в качестве единой платформы и **GitLab CI/CD** в качестве движка непрерывной интеграции и поставки. Это решение полностью покрывает все ваши требования и обеспечивает высокую степень интеграции "из коробки".

**Архитектура решения:**

1.  **GitLab Self-Managed** (развернутый в вашем облаке) — для контроля версий, управления проектами и CI/CD.
2.  **GitLab CI/CD** — встроенный движок непрерывной интеграции и поставки.
3.  **Docker Registry** (встроенный в GitLab) — для хранения кастомных образов для сборки.
4.  **GitLab Runners** — агенты, которые выполняют jobs. Будут развернуты на собственных серверах в облаке.

---

### Обоснование выбора и соответствие требованиям

Давайте разберем каждое требование и посмотрим, как его закрывает GitLab.

| Требование                                                          | Реализация в GitLab                                                                                                                                                                                                                                                                                        | Обоснование                                                                                                                                                           |
| :------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Облачная система**                                                | GitLab доступен как SaaS на [gitlab.com](https://gitlab.com) (облако GitLab) или может быть развернут как **Self-Managed** в любом публичном облаке (AWS, GCP, Azure).                                                                                                                                     | Позволяет выбрать модель развертывания: полностью управляемый сервис или полный контроль в своем облаке. Соответствует требованию "облачная система" в обоих случаях. |
| **Система контроля версий Git**                                     | GitLab — это одна из ведущих платформ для хостинга Git-репозиториев.                                                                                                                                                                                                                                       | Соответствие на 100%.                                                                                                                                                 |
| **Репозиторий на каждый сервис**                                    | В GitLab каждый микросервис — это отдельный **Project**. Группы сервисов можно объединять в **Groups**.                                                                                                                                                                                                    | Идеальная модель для микросервисов. Позволяет изолировать код, настройки CI/CD и права доступа для каждого сервиса.                                                   |
| **Запуск сборки по событию из системы контроля версий**             | GitLab CI/CD автоматически запускает пайплайн при любом пуше в репозиторий (в любую ветку), при создании Merge Request и т.д.                                                                                                                                                                              | Базовая функциональность CI/CD. Настраивается в файле `.gitlab-ci.yml`.                                                                                               |
| **Запуск сборки по кнопке с указанием параметров**                  | **Pipeline Schedules** + **Manual Actions** + **CI/CD Variables**. Можно создать кнопку (`when: manual`), при нажатии на которую будет запущен джоб, и передать ему переменные.                                                                                                                            | Очень гибкий механизм. Позволяет, например, вручную запустить деплой на прод, указав версию образа.                                                                   |
| **Возможность привязать настройки к каждой сборке**                 | **CI/CD Variables**. Можно задавать переменные на уровне проекта, группы или всего инстанса. Они безопасно передаются в среду выполнения пайплайна.                                                                                                                                                        | Позволяет конфигурировать сборки без изменения кода (например, версии, флаги, URLs).                                                                                  |
| **Возможность создания шаблонов для различных конфигураций сборок** | **1. `include:`** — возможность включить внешний YAML-файл (из другого репозитория или URL).<br>**2. `extends:`** — наследование шаблонов джобов.<br>**3. Hidden Jobs (начинаются с `.`)** — создание шаблонов джобов, которые не выполняются сами по себе.                                                | Мощный и гибкий механизм для устранения дублирования кода в `.gitlab-ci.yml`. Позволяет создать централизованные библиотеки шаблонов для всех команд.                 |
| **Возможность безопасного хранения секретных данных**               | **1. CI/CD Variables** с пометкой "Masked" (маскируются в логах) и "Protected" (доступны только для защищенных веток/тегов).<br>**2. Integrated Kubernetes Cluster Integration** для хранения секретов.<br>**3. HashiCorp Vault Integration** — нативная интеграция для продвинутого управления секретами. | Полноценная поддержка безопасности секретов на уровне платформы. Masked Variables — must-have функция для защиты паролей и ключей.                                    |
| **Несколько конфигураций для сборки из одного репозитория**         | В файле `.gitlab-ci.yml` можно описать множество джобов (`build`, `test`, `deploy`). Используя **Rules** или **Only/Except**, можно задать условия их выполнения (например, для разных веток, тегов, по наличию файла).                                                                                    | Позволяет иметь один пайплайн, который ведет себя по-разному для feature-веток, main-ветки и тегов.                                                                   |
| **Кастомные шаги при сборке**                                       | Файл `.gitlab-ci.yml` описывает пайплайн как последовательность **jobs**. Каждый job состоит из набора **script**, которые выполняются один за другим.                                                                                                                                                     | Любые shell-команды или скрипты могут быть шагами сборки. Полная свобода действий.                                                                                    |
| **Собственные докер-образы для сборки проектов**                    | Ключевое слово **`image`** в `.gitlab-ci.yml` позволяет указать любой Docker-образ для запуска джоба. Можно использовать образы из GitLab Container Registry, Docker Hub или любого другого registry.                                                                                                      | Стандартная практика. Обеспечивает воспроизводимость и консистентность окружения сборки.                                                                              |
| **Возможность развернуть агентов на собственных серверах**          | **GitLab Runner** — это отдельное приложение, которое легко устанавливается на любую машину (VM, bare-metal, k8s) и регистрируется в GitLab. Поддерживает Docker, Kubernetes, Shell и другие исполнители.                                                                                                  | Дает полный контроль над инфраструктурой для сборки. Можно выбрать мощные инстансы для тяжелых сборок, использовать кеши и образы из локальной сети.                  |
| **Возможность параллельного запуска нескольких сборок**             | Несколько пайплайнов, запущенных от разных коммитов или в разных проектах, будут выполняться параллельно, если есть доступные **GitLab Runners**.                                                                                                                                                          | Архитектура "один координатор (GitLab) — множество воркеров (Runners)" по умолчанию поддерживает параллелизм.                                                         |
| **Возможность параллельного запуска тестов**                        | Ключевое слово **`parallel`** в джобе позволяет запустить несколько инстансов одного и того же джоба параллельно. Идеально для разделения тестовой суты на части.                                                                                                                                          | Значительно ускоряет выполнение длительных тестов, распределяя нагрузку по нескольным runner'ам.                                                                      |

---

### Альтернативные решения

Хотя GitLab является комплексным решением, иногда могут рассматриваться и другие варианты:

1.  **GitHub + GitHub Actions:**
    *   **Плюсы:** Огромная популярность, глубокие интеграции, мощный Marketplace.
    *   **Минусы:** Некоторые функции, как шаблоны пайплайнов, могут быть менее гибкими. Self-hosted runners (аналоги GitLab Runners) есть. Безопасное хранение секретов также присутствует.

2.  **Bitbucket + Bitbucket Pipelines:**
    *   **Плюсы:** Хорошая интеграция с Jira, простой setup.
    *   **Минусы:** Менее богатый функционал по сравнению с GitLab и GitHub, особенно в области продвинутого управления пайплайнами.

3.  **Связка Jenkins + GitHub/GitLab:**
    *   **Плюсы:** Максимальная гибкость и кастомизация, огромное количество плагинов.
    *   **Минусы:** Требует значительных усилий по поддержке и настройке ("Jenkins как питомец"). Нет единой интегрированной платформы, что усложняет управление.

### Заключение и рекомендация

**GitLab** я считаю оптимальным выбором для вашей задачи по следующим причинам:

*   **Единая платформа:** Он предоставляет полностью интегрированное решение (Git-репозиторий, CI/CD, Issue Tracking, Container Registry) "из коробки". Это снижает operational overhead и упрощает управление.
*   **Полное соответствие требованиям:** Как было показано выше, GitLab покрывает все пункты вашего ТЗ без необходимости привлечения сторонних инструментов.
*   **Идеальная модель для микросервисов:** Группы и проекты идеально ложатся на структуру микросервисов.
*   **Гибкость развертывания:** Вы можете начать с GitLab.com (SaaS), а по мере роста мигрировать на Self-Managed в своем облаке без смены логики работы CI/CD.
*   **Мощный и современный CI/CD:** GitLab CI/CD использует декларативный подход на основе YAML, который является современным стандартом, и при этом предоставляет всю необходимую гибкость.

**Мое итоговое предложение:** Развернуть **GitLab** в режиме Self-Managed в вашем облаке (например, в Kubernetes-кластере в AWS) для полного контроля и использования всех функций Enterprise-уровня. Зарегистрировать собственные **GitLab Runners** в этом же кластере или на выделенных виртуальных машинах, чтобы обеспечить масштабируемость и производительность сборок.
---------------------

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.
-------------------------

## Решение №2

Предлагаемое решение: Модифицированный стек EFK

Я предлагаю использовать связку **Fluent Bit** → **Kafka** → **Fluentd** → **Elasticsearch** → **Kibana**.

**Архитектура решения:**

1.  **Агент на каждом хосте (Fluent Bit):** Легковесный агент, который собирает логи из `stdout`/файлов и пересылает их.
2.  **Буфер/Брокер сообщений (Apache Kafka):** Обеспечивает гарантированную доставку и буферизацию пиковых нагрузок.
3.  **Обработчик и агрегатор (Fluentd):** Принимает логи из Kafka, парсит, структурирует, обогащает метаданными и отправляет в Elasticsearch.
4.  **Хранилище и поисковый движок (Elasticsearch):** База данных для логов, обеспечивающая индексирование, молниеносный поиск и фильтрацию.
5.  **Веб-интерфейс (Kibana):** Пользовательский интерфейс для визуализации, поиска и анализа логов, а также создания дашбордов.

```
[Сервисы (stdout)] --> [Docker Driver/Journald] --> [Fluent Bit] --> [Apache Kafka] --> [Fluentd] --> [Elasticsearch] <--> [Kibana (UI)]
```

---

### Обоснование выбора и соответствие требованиям

Разберем, как каждый компонент закрывает ваши требования.

| Требование                                                     | Реализация в предложенном стеке                                                                                                                                                                                                                             | Обоснование                                                                                                                                                                |
| :------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Сбор логов в центральное хранилище со всех хостов**          | **Fluent Bit** развертывается как DaemonSet в Kubernetes или как системный сервис на каждой VM. Он гарантированно собирает логи со своего узла и отправляет их дальше в Kafka.                                                                              | DaemonSet (K8s) или systemd-сервис (VM) гарантирует, что агент будет работать на каждом хосте.                                                                             |
| **Минимальные требования к приложениям, сбор логов из stdout** | Приложения пишут логи **только в stdout/stderr**. Fluent Bit собирает их либо из файлов (`/var/log/containers/*.log`), либо напрямую из журнала systemd (`journald`), либо через Docker JSON logging driver.                                                | Это стандартная и рекомендуемая практика для контейнеризованных приложений (12-factor app). Приложение не заботится о маршрутизации логов, этим занимается инфраструктура. |
| **Гарантированная доставка логов**                             | **Apache Kafka** выступает как высокодоступный и устойчивый буфер. Fluent Bit использует встроенные плагины вывода для Kafka с поддержкой подтверждений (acknowledgments). При падении Elasticsearch или Fluentd логи накапливаются в Kafka, а не теряются. | Kafka спроектирована для гарантированной доставки сообщений и работы с пиковыми нагрузками. Это защищает систему от потери данных при сбоях бэкенда.                       |
| **Обеспечение поиска и фильтрации**                            | **Elasticsearch** — это поисковый движок №1 для логов. Он индексирует каждое поле из JSON-логов. Это позволяет выполнять сложные запросы с фильтрацией по любому полю (например, `service_name:auth-service AND level:ERROR AND response_code:500`).        | Мощный язык запросов (Lucene Query Syntax) и высочайшая скорость поиска даже по терабайтам данных.                                                                         |
| **Пользовательский интерфейс для разработчиков**               | **Kibana** — это стандартный веб-интерфейс для Elasticsearch. Разработчикам предоставляется доступ к Kibana, где они могут использовать интерфейс "Discover" для интерактивного поиска по логам.                                                            | Интуитивно понятный UI, не требующий знания запросов к Elasticsearch. Можно создавать и сохранять дашборды для мониторинга конкретных сервисов.                            |
| **Ссылка на сохранённый поиск**                                | В Kibana есть функционал **"Saved Searches"**. Любой поиск с фильтрами можно сохранить и получить на него прямую ссылку, которой можно поделиться.                                                                                                          | Позволяет быстро делиться контекстом ошибки. Например, можно создать сохраненный поиск по ошибкам конкретного сервиса и вставить ссылку в тикет или Slack.                 |

---

### Детализация роли каждого компонента

*   **Fluent Bit (вместо Filebeat/Logstash Forwarder):**
    *   **Почему он?** Чрезвычайно легковесный (требует ~1MB памяти), написан на C, и обладает высокой пропускной способностью. Идеально подходит для работы на edge-нодах.
    *   **Задача:** Сбор, минимальная парсировка (например, извлечение времени, уровня лога) и надежная отправка в Kafka.

*   **Apache Kafka:**
    *   **Задача:** Принять логи от сотен Fluent Bit-агентов, буферизовать их и равномерно отдавать потребителям (Fluentd). Отвечает за **гарантированную доставку** и **сглаживание нагрузки**.

*   **Fluentd (вместо Logstash):**
    *   **Почему он?** Более эффективен с памятью и хорошо показывает себя в production-окружениях для агрегации. Имеет богатую экосистему плагинов.
    *   **Задача:** Чтение логов из Kafka, парсинг сложных структур (например, парсинг stack trace), обогащение (добавление полей `hostname`, `environment`, `service_name` на основе Kubernetes-меток), и окончательная запись в Elasticsearch.

*   **Elasticsearch:**
    *   **Задача:** Хранение, индексация и предоставление API для поиска по всем логам. Развертывается в виде кластера для обеспечения отказоустойчивости и масштабируемости.

*   **Kibana:**
    *   **Задача:** Визуализация логов. Предоставляет интерфейс для разработчиков и DevOps-инженеров.

### Альтернативные решения

1.  **Классический ELK/Elastic Stack (Filebeat → Logstash → Elasticsearch → Kibana):**
    *   **Плюсы:** Официальный стек от Elastic, отличная документация и сообщество.
    *   **Минусы:** Logstash (на JRuby) может быть более "тяжелым" по потреблению ресурсов по сравнению с Fluentd, особенно в роли агрегатора.

2.  **Grafana Loki Stack (Promtail → Loki → Grafana):**
    *   **Плюсы:** Очень легковесный, дешевый в хранении, идеально интегрирован с Grafana. Индексирует только метки, а не полный текст, что делает его эффективным для хранения.
    *   **Минусы:** Менее мощный полнотекстовый поиск по сравнению с Elasticsearch. Моложе и менее зрелый, чем ELK. Может не подойти для сложных запросов по содержимому логов.

### Заключение и рекомендация

Предложенный стек **Fluent Bit → Kafka → Fluentd → Elasticsearch → Kibana** является production-ready решением, которое используется в тысячах высоконагруженных компаний.

*   **Оно надежно** за счет буферизации в Kafka.
*   **Эффективно** за счет использования легковесного Fluent Bit на нодах.
*   **Мощно** за счет поисковых возможностей Elasticsearch.
*   **Удобно для разработчиков** за счет интуитивного интерфейса Kibana.  


## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.  
---------------------------
## Решение №3

Для комплексного мониторинга микросервисной архитектуры я предлагаю использовать современный, широко распространенный и мощный стек на основе **Prometheus** и **Grafana**.

### Предлагаемое решение: Стек Prometheus + Grafana

Это решение де-факто является стандартом для мониторинга в cloud-native средах.

**Архитектура решения:**

1.  **Сбор метрик (Prometheus):** Основной компонент, который "вытягивает" (pull model) метрики с различных источников.
2.  **База данных временных рядов (Prometheus TSDB):** Встроенное высокопроизводительное хранилище, оптимизированное для метрик.
3.  **Визуализация и дашборды (Grafana):** Мощная платформа для визуализации, построения дашбордов и анализа данных.
4.  **Экспортеры метрик (Node Exporter, cAdvisor и кастомные):** Небольшие приложения, которые трансформируют данные с хостов и сервисов в формат, понятный Prometheus.
5.  **(Опционально) Механизм оповещений (Alertmanager):** Компонент для управления и роутинга алертов от Prometheus.

```
[Приложения (/metrics)] <--+
[Node Exporter (host)]     |  <-- Pull -- [Prometheus Server] --> [Alertmanager] --> (Slack, Email, PagerDuty)
[cAdvisor (containers)]    |
[Кастомные экспортеры]  --+
                              |
[Grafana] <-- Dashboards -- [Prometheus API]
```

---

### Обоснование выбора и соответствие требованиям

Разберем, как каждый компонент закрывает ваши требования.

| Требование                                                | Реализация в стеке Prometheus + Grafana                                                                                                                                                                                                                                                                                                     | Обоснование                                                                                                                                                                                       |
| :-------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Сбор метрик со всех хостов**                            | **Prometheus Server** периодически опрашивает (scrape) по HTTP все целевые хосты (targets), указанные в его конфигурации. Для автоматического обнаружения целей в Kubernetes используется **Service Discovery**.                                                                                                                            | Pull-модель централизует конфигурацию и упрощает управление. Service Discovery в K8s автоматически находит новые поды и сервисы.                                                                  |
| **Сбор метрик состояния ресурсов хостов**                 | **Node Exporter** — это стандартный экспортер, который запускается на каждом хосте (как DaemonSet в K8s) и предоставляет метрики по CPU, RAM, HDD, Network и сотни других в формате, готовом для сбора Prometheus.                                                                                                                          | Де-факто стандарт для сбора системных метрик. Легковесный и надежный.                                                                                                                             |
| **Сбор метрик потребляемых ресурсов для каждого сервиса** | **cAdvisor (Container Advisor)** — собирает метрики по использованию ресурсов на уровне контейнеров (CPU, RAM, HDD, Network). В Kubernetes он встроен в Kubelet, поэтому Prometheus может собирать эти метрики напрямую.                                                                                                                    | Позволяет видеть потребление ресурсов не просто хоста, а каждого конкретного пода/контейнера, что критически важно в микросервисной архитектуре.                                                  |
| **Сбор метрик, специфичных для каждого сервиса**          | **1. Встроенная инструментация:** Приложения должны предоставлять эндпоинт `/metrics` в формате Prometheus. Для этого используются клиентские библиотеки (Go, Java, Python, etc.).<br>**2. Экспортеры:** Для сторонних сервисов (БД, очереди, веб-серверы) используются готовые экспортеры (например, `mysqld_exporter`, `nginx_exporter`). | Prometheus не навязывает формат метрик, что дает полную свободу в их определении. Это идеально подходит для бизнес-метрик (например, `orders_processed_total`, `http_requests_duration_seconds`). |
| **Пользовательский интерфейс с запросами и агрегацией**   | **Prometheus Web UI** предоставляет базовый интерфейс для выполнения запросов на мощном языке **PromQL (Prometheus Query Language)**. PromQL позволяет агрегировать, фильтровать, производить математические операции и прогнозирование.                                                                                                    | PromQL — это один из самых мощных инструментов в арсенале Prometheus. Позволяет отвечать на сложные вопросы о поведении системы.                                                                  |
| **Пользовательский интерфейс с настраиваемыми панелями**  | **Grafana** — это лучший в своем классе инструмент для визуализации. Она подключается к Prometheus как к источнику данных и позволяет создавать богатые, интерактивные дашборды с графиками, таблицами, heatmaps и т.д. Дашборды можно настраивать под нужды каждой команды.                                                                | Grafana является стандартом для визуализации метрик. Поддерживает шаблонизацию, аннотации, управление доступом и огромное количество плагинов.                                                    |

---

### Детализация роли каждого компонента

*   **Prometheus Server:**
    *   **Задача:** Ядро системы. Отвечает за сбор, хранение и обработку метрик. Его основная работа — ходить по списку целей и "вытягивать" с них данные.
    *   **Ключевая особенность:** Мультидименсионная data-модель на основе key-value пар (labels). Метрика `http_requests_total` может иметь лейблы `method="POST"`, `handler="/api/v1/order"`, `status="500"`, что делает агрегацию и фильтрацию невероятно гибкими.

*   **Grafana:**
    *   **Задача:** Предоставить пользователям (разработчикам, DevOps, менеджерам) удобный и наглядный доступ к данным. Позволяет создавать общие дашборды для отслеживания состояния всей системы или специализированные для отдельных сервисов.
    *   **Ключевая особенность:** Поддержка множества источников данных (не только Prometheus), мощный конструктор графиков, система оповещений и возможность делиться дашбордами.

*   **Node Exporter & cAdvisor:**
    *   **Задача:** Быть "переводчиками" между операционной системой/контейнерами и Prometheus. Они превращают данные из `/proc` и `sysfs` в HTTP-эндпоинт с текстовым форматом.

*   **Alertmanager (дополнительно, но настоятельно рекомендуется):**
    *   **Задача:** Обрабатывать алерты, отправленные Prometheus, выполнять их группировку, подавление (например, если падает хост, не нужно получать 100 алертов о падении всех его сервисов) и маршрутизацию на правильные каналы (Slack, Email, PagerDuty).

### Альтернативные решения

1.  **Связка TICK Stack (Telegraf, InfluxDB, Chronograf, Kapacitor):**
    *   **Плюсы:** Единый стек от одного вендора (InfluxData), InfluxDB имеет мощный SQL-подобный язык запросов (Flux).
    *   **Минусы:** Меньшее распространение и сообщество по сравнению с Prometheus. Менее тесная интеграция с Kubernetes "из коробки".
2.  **Zabbix / Nagios:**
    *   **Плюсы:** Зрелые, проверенные временем решения с мощными возможностями оповещения.
    *   **Минусы:** Архитектура и data-модель не так хорошо подходят для высокодинамичной среды микросервисов, как у Prometheus. Чаще используются для мониторинга классической инфраструктуры.

### Заключение и рекомендация

Стек **Prometheus + Grafana** является идеальным выбором для мониторинга микросервисной архитектуры по следующим причинам:

*   **Cloud-Native:** Спроектирован для динамических сред, таких как Kubernetes, с автоматическим обнаружением сервисов.
*   **Мощная модель данных:** Метки (labels) позволяют легко агрегировать и фильтровать метрики по множеству измерений (сервис, версия, хост, зона и т.д.).
*   **Экосистема:** Огромное количество готовых экспортеров, дашбордов и интеграций.
*   **Простота и надежность:** Компоненты просты в развертывании и эксплуатации.
*   **Сообщество:** Самое большое и активное сообщество, что означает быструю помощь, обширную документацию и готовые рецепты.

**Мое итоговое предложение:** Развернуть **Prometheus Stack** (например, с помощью Helm-чарта `kube-prometheus-stack`) в вашем Kubernetes-кластере. Этот чарт включает в себя Prometheus, Grafana, Alertmanager, Node Exporter и все необходимые настройки Service Discovery "из коробки". Это обеспечит полное покрытие всех ваших требований к мониторингу с минимальными затратами на внедрение.
-------------------------

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
